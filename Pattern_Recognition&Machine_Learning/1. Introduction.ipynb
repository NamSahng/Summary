{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.  Introduction\n",
    "\n",
    "Generalization: 사용되지 않았던 새로운 예시들을 올바르게 분류하는 능력\n",
    "\n",
    "### 1.1 다항식 곡선(Polynomial Curve)\n",
    "\n",
    "우리의 목표는 training set을 사용해 새로운 입력값 $\\hat{x}$이 주어졌을 때, Target Variable $\\hat{t}$를 예측하는 것이다. 우리가 앞으로 살펴볼 것처럼 기저에 있는 함수 $sin(2{\\pi}x)$를 찾아내는 것이 예측과정에 암시적으로 포함된다. 이는 한정된 데이터 집합으로부터 Generalization을 시행하는 과정이 필요하기 때무에 본질적으로 어려운 문제이다. 게다가 Observed data들은 Noise로 인해 변질되어 있어서 각각의 주어진 $\\hat{x}$에 대해 어떤 값이 적합한 $\\hat{t}$인지 불확실하다.\n",
    "\n",
    "확률론(1.2)에서는 이러한 불확실성을 정확하고 정량적으로 표현하는데 도움을 주고 \n",
    "의사결정이론(1.5)에서는 특정 기준에 따라 최적의 예측을 하는 데 확률적인 표현을 활용할 수 있게 해준다.\n",
    "\n",
    "- $sin(2{\\pi}x)$에서 random noise 섞은 데이터가 10 개일 때\n",
    "\n",
    "9차에서 오차 0 $\\to$ 당연, 해당 다항식은 $w_0$ ~ $w_9$까지 10차의 자유도를 갖고 있고 데이터도 10개이므로 but Overfitting\n",
    "\n",
    "데이터가 많으면, 복잡한(유연한) 모델을 활용한 피팅이 가능. 모델의 복잡도를 측정하는데 매개변수의 숫자만을 사용하는 것이 아닌 더 적합한 방법이 존재한다. (3장 선형회귀모델, Linear Regression Model)\n",
    "\n",
    "지금의 예시에서 사용한 최소제곱법(least squares approximation)은 최대 가능도(Maximum Liklihood 1.2.5)의 특별한 사례이다. Overfitting 문제는 Maximum Liklihood 방법의 성질 중 하나로써 이해가 가능하다. Bayesian 방법론을 채택하면 과적합 문제를 피할 수가 있다. Bayesian 관점에서는 데이터 포인트의 숫자보다 매개변수의 숫자가 훨씬 더 많은 모델을 사용해도 문제가 없다는 것을 앞으로 볼 것이다. Bayesian 모델에서는 데이터 집합의 크기에 따라서 적합한 매개변수의 수가 자동으로 정해진다.\n",
    "\n",
    "비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용해 Fitting 할 때 자주 사용되는 기법이 Regularization 이다. Error Function에서 penalty항을 추가하는 것이다.\n",
    "\n",
    "$\\tilde{E}(w) = {1\\over 2}{\\Sigma \\{ y(x_{n},\\mathbf{w}) - t_{n} \\} ^{2} + {\\lambda \\over 2}  {\\parallel}{\\mathbf{w}}{\\parallel}^2  }$\n",
    "\n",
    "$ {\\parallel}{\\mathbf{w}}{\\parallel}^2 \\equiv {\\mathbf{w}}^{T}{\\mathbf{w}} = w^{2}_{0} + w^{2}_{1} + w^{2}_{2} + ... + w^{2}_{M}   $이고 계수  ${\\lambda}$ 가 정규화항의 제곱합 Error Function에 대한 상대적인 중요도를 결정짓는다. ${w_{0}}$을 포함하면 Target Variable의 원점을 무엇으로 선택택하느냐에 대해 결과가 종속되므로, 종종 ${w_{0}}$는 정규화항에서 제외한다. ${w_{0}}$만 따로 빼내어 별도의 정규화 계수와 함께 다른 항을 만들어 포함하기도 한다. (5장 5.1)\n",
    "\n",
    "$\\tilde{E}(w)$ 의 최솟값을 찾는 문제 역시 닫힌 형식이기 때문에 앞에서 미분을 통해 유일해를 찾아낼 수 있다. 통계학에서는 계수의 크기를 수축시키는 방법을 사용하여 수축법(Shrinkage Method)라고 하고, Quadratic(이차 형식) 정규화는 Ridge Regression이라고 부룬다. Neural Network의 맥락에서는 이를 Weight Decay(가중치 감쇠)라 한다.\n",
    "\n",
    "위에서 M = 9 일 때, Overfitting이 일어난 식에 $ln\\lambda = -18$ 을 적용하면 Overfitting을 피할 수 있다. 그러나 람다가 너무 크면 좋지 않다. 모델의 복잡도와 람다의 관계는 1.3 에서 자세히 본다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### 1.2 확률론\n",
    "\n",
    "Pattern Recognition 에서 중요한 concept 중 하나는 바로 **Uncertainty** 이다. <br> \n",
    "불확실성은 측정할 때의 노이즈를 통해서도 발생하고, 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.<br>\n",
    "확률론은 불확실성을 계량화하고 조작하기 위한 이론적인 토대를 마련하며, 패턴 인식의 중요한 기반이다.<br>\n",
    "1.5절의 의사결정이론과 확률론을 통해, 주어진 정보가 불확실하거나 완전하지 않은 제약 조건하에서 최적의 예측을 시행할 수 있게 한다.\n",
    "\n",
    "<hr/>\n",
    "* Sum Rule & Product Rule\n",
    "<br>\n",
    "Sum Rule : $p(X = x_{i}, Y = y_{i}) = {n_{ij} \\over N }$ 일 때, &nbsp; $p(X = x_{i}) = {\\sum_{j = 1}^L}p(X = x_{i}, Y = y_{i}) $ 이 때,  $p(X = x_{i})$를 Marginal probability(주변확률)라고 불린다.\n",
    "<br> \n",
    "Product Rule : $p(X = x_{i}, Y = y_{j}) = {n_{ij} \\over N} = {{n_{ij}\\over c_{i}} \\cdot {c_{i} \\over N} = p(Y = y_{j}|X=x_{i})p(X=x_{i}) }$\n",
    "\n",
    "* Bayes' Theorem\n",
    "<br>\n",
    "곱의 법칙과 대칭성 $p(X,Y) = p(Y,X)$ 로부터 베이즈 정리를 도출할 수 있다.<br>\n",
    "$p(Y|X) = {p(X|Y)p(Y) \\over p(X)}$\n",
    "\n",
    "ex) Red Basket에 오렌지 6개, 사과 2개 / Blue Basket에 오렌지 1개, 사과 3개 / $p(B = red)$ = 4/10 , $p(B = blue)$ = 6/10\n",
    "<br>\n",
    "어떤 과일이 선택되었는지를 알기 전에 어떤 박스를 선택했냐고 묻는다면 그 확률은 어떤 과일이 선택되었는지 관찰하기 '전'의 확률 == 사전확률(Prior Probability) p(B)라고 한다. \n",
    "<br>\n",
    "선택된 과일이 오렌지라는 것을 알게 된다면 Bayes' Theorem을 활용해 $p(B|F)$를 구할 수 있고 이는 사후확률(Posterior Probability) 이다.\n",
    "<br>\n",
    "예시에서 빨간색 상자를 고를 사전확률은 4/10 이므로 파란색 상자를 고를 확률이 더 높다. 그러나 선택된 과일이 오렌지라는 것을 확인하고 난 후 빨간색 상자를 고를 사후 확률이 2/3이므로 우리가 고른 상자가 빨간색 상자이었을 확률이 더 높게 된다. 따라서 고른 과일이 오렌지였다는 관측결과가 고른 상자가 빨간색일 가능성으르 높여주는 우리의 직관과 일치한다. 오렌지를 골랐다는 증거가 강력해 사전지식을 뒤엎고 빨간 상자를 골랐을 확률을 높게 만들어 주는 것이다.\n",
    "<br>\n",
    "$p(F|B) = p(F)$가 된다. 과일을 고를 확률은 어떤 상자를 골랐는 지와는 독립이다.\n",
    "\n",
    "* 1.2.1 Probability density (확률밀도)\n",
    "\n",
    "연속적인 변수에서의 확률을 알아보자. 실수 변수 x가 $(x,x+\\delta x)$ 구간 안의 값을 갖고 그 변수의 확률이 $p(x)\\delta x (\\delta x \\to 0 일\\  경우) $로 주어진다면, p(x)를 x의 확률밀도(probability density)라고 부른다. 이때 x가 (a,b) 구간 사의 값을 가질 확률은 다음과 같이 주어진다.\n",
    "<br>\n",
    "$$p(x \\in (a,b)) = {\\int_{a}^{b} p(x)dx} $$\n",
    "<br>\n",
    "그리고  다음 두 조건을 만족해야한다. $p(x)\\ \\geqslant 0$ and $\\int_{-\\infty}^{\\infty}p(x)dx = 1 $\n",
    "\n",
    "확률 분포(probability distribution) 함수는 야코미안 인자로 인해서 비선형 변수 변환 시에는 일반적인 단순 함수와는 다른 방식으로 변화하게 된다. 예를들어, $x = g(y)$의 변수 변환을 고려해 보자. 그러면 함수 $f(x)$는 $\\tilde{f}(y) = f(g(y))$가 된다. x의 확률밀도함수(PDF) $p_{x}(x)$와 새로운 변수 y의 PDF $p_{y}(y)$를 살펴보면 둘이 다른 확률밀도를 가진 다는 것이 자명하다.<br>\n",
    "$(x,x+\\delta x)$범위에 속하는 관찰값(아주 작은 $\\delta x$에 대해)은 범위 $(y,y+\\delta y)$로 변환될 것이며, 이때 $p_{x}(x)\\delta x \\simeq\n",
    "p_{y}(y)\\delta y$다. 따라서 다음과 같다.\n",
    "$${p_{y}(y) = p_{x}(x) \\left|{dx \\over dy  }\\right| = p_{x}(g(y)) \\left|g^{\\prime}(y)\\right| }$$\n",
    "이로부터, 확률 밀도의 최댓값은 어떤 변수를 선택하는지에 따라 달라짐을 알 수 있다.\n",
    "x가 $(-\\infty,z)$ 범위에 속할 확률은 누적 분포 함수(CDF)로 표현된다.\n",
    "$$P(z) = \\int_{-\\infty}^{z} p(x)dx $$\n",
    "따라서, 확률 밀도는 누적분포함수의 미분으로 표현할 수 있다.\n",
    "만약 여러 개의 연속적인 변수가 주어지고 변수들이 벡터 x로 표현될 경우에도 적분을 전체 x 공간에 대해 시행한다.<br> 만약 x가 이산 변수일 경우 p(x)를 확률질량함수라고 부르기도 한다. 연속변수의 확률밀도와 이산변수와 연속변수가 조합된 경우의 확률 밀도에도 합의 법칙, 곱의 법칙, 베이지안 정리를 적용할 수 있다. ex) $p(x) = \\int p(x,y)dy \\ \\ \\ \\ \\ \\ \\ \\ \\ p(x,y) = p(y|x)p(x)$ <br>\n",
    "연속변수의 합과 곱의 법칙에 대해 정식으로 정의를 내리기 위해서는 **측도이론(measure theory)**에 대해 살펴봐야한다. 간략히 설명하면 측도이론에서 각각의 실수 변수를 폭 $\\Delta$인 범위들로 쪼개고 각각의 범위를 이산 확률 분포로 간주한다. 여기서 $lim \\Delta \\to 0$를 취하고 합을 적분으로 바꾸면 우리가 원하는 결과를 얻는다.\n",
    "\n",
    "\n",
    "* 1.2.2 기댓값과 공분산 (Expectation & Covariance)\n",
    "\n",
    "확률과 관련된 가장 중요한 계산 중 하나는 함숫값들의 가중 평균을 구하는 것이다. 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값은 f(x)의 기댓값(Expectation)이라 하며, $\\mathbb{E}[f]$라 적는다.\n",
    "$$ \\mathbb{E}[f] = \\sum_{x} p(x)f(x) \\qquad \\mathbb{E}[f] = \\int p(x)f(x)   $$\n",
    "각각 이산분포 연속분포일 경우 이다.\n",
    "<br>\n",
    "만약 유한한 N개의 포인트를 확률 분포 또는 확률 밀도에서 추출 했다면, 이산/연속 모든 경우에 각 포인트들의 유한한 합산으로 기댓값을 근사할 수 있다.\n",
    "$$ \\mathbb{E}[f]  \\simeq {1\\over N} \\sum_{n=1}^{N}f(x_{n})  $$\n",
    "11장 표본추출방법론에서 이 결과를 많이 활용한다.(기계학습개론 week 10 Sampling Based Inference) 위 식에서 $lim N \\to \\infty$일 때 정확한 값이 된다.<br>\n",
    "다변수 함수의 기댓값을 구할 경우에는 어떤 변수에 대해 평균을 내는지 지정하여 계산할 수 있다. f(x,y)의 평균값을 x의 분포에 대해 구하라는 것은 $\\mathbb{E}_{x}[f(x,y)]$ 이다. 조건부 분포에 해당하는 조건부 기댓값(conditional expectation)은  $\\mathbb{E}_{x}[f(x|y)] = \\sum_{x}p(x|y)f(x)$이며, 연속변수에서도 마찬가지로 정의 가능하다.\n",
    "\n",
    "분산(Variance)은 다음과 같이 정의된다.\n",
    "$$var[f] = \\mathbb{E}[(f(x)- \\mathbb{E}[f(x)])^{2}]$$\n",
    "위 식을 전개하면 분산을 $f(x)$와 $f(x)^2$의 기댓값으로 표현가능하다. $var[f] = \\mathbb{E}[f(x)^{2}] - \\mathbb{E}[f(x)]^2$ <br>\n",
    "변수 x 그 자체로는 $var[x] = \\mathbb{E}[x^{2}] - \\mathbb{E}[x]^2$ 이다.\n",
    "\n",
    "두 개의 확률 변수 x와 y에 대한 공분산(covariance)는 다음과 같이 정의된다.\n",
    "$$var[x,y] = \\mathbb{E}_{x,y}[(x - \\mathbb{E}[x])(y - \\mathbb{E}[y])]  = \\mathbb{E}_{x,y}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]$$\n",
    "공분산은 x값과 y값이 얼마나 함께 변동하는 가의 지표이며, 만약 x와 y가 서로 독립일 경우 공분산값은 0으로 간다.<br>\n",
    "두 확률 변수 x,y 가 벡터일 경우 공분산은 행렬이 된다.\n",
    "$$var[x,y] = \\mathbb{E}_{x,y}[(x - \\mathbb{E}[x])(y^{T} - \\mathbb{E}[y^{T}])]  = \\mathbb{E}_{x,y}[xy^{T}] - \\mathbb{E}[x]\\mathbb{E}[y^{T}]$$\n",
    "\n",
    "1.2.3 베이지안 확률 (Bayesian Probability)\n",
    "\n",
    "Q. What is probability?<br>[1]\n",
    "$\\to$ a. ** Frequentistic view ** : It is the ** relative frequency ** with which outcom would be obtained if the process were repeated a large number of times under similar conditions. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;b. Bayesian: It is your degree of belief in an outcome. \n",
    "\n",
    "'북극의 빙하가 이번 세기말까지 다 녹아 없어진다'는 사건을 생각 해보면 여러 번 반복할 수 없어 앞에서 본 과일 상자와 같은 방식으로 확률을 정의하는 것이 불가능하다. 그러나 우리는 이러한 사건들에 '북극의 얼음이 어러저러한 속도로 녹는다'와 같은 견해가 있으며 새로운 증거를 추가할 수 있다면 얼음이 녹는 속도에 대한 우리의 의견을 수정할 수 있다. 그리고 이러한 상황들에서 우리는 주어진 불확실성을 정량화할 수 있으며 새 증거가 주어질 때마다 불확실성을 수정해 최적의 선택을 내리게 해주는 일반적인 방법론이 확률의 베이지안 해석이다.\n",
    "\n",
    "확률에 대한 개념을 일반적으로 확장하는 것은 패턴인식에서 큰 도움이된다. 1.1절의 다항식 곡선 피팅에서 관찰값 $t_{n}$에 대해서는 확률의 Frequentistic 관점이 적합해 보일 수 있다. 그러나 적합한 모델 매개변수 w를 정하는 데 있어 불확실성을 수치화하고 표현하려면 베이지안 관점을 사용하면 확률론의 다양한 장치들을 활용해 w와 같은 모델 매개변수의 불확실성을 설명할 수 있다. 더불어 베이지안 관점은 모델 그 자체를 선택하는데 있어서도 유용하다.\n",
    "\n",
    "MLE MAP 설명 <주소> [1]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br><br>\n",
    "### Reference:\n",
    "\n",
    "Christopher M. Bishop, 패턴인식과 기계학습 \n",
    "<br>\n",
    "[1] 문일철 교수님, 인공지능 및 기계학습 개론Ⅰ Week 1,7, https://www.edwith.org/machinelearning1_17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
