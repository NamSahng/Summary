{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.  Introduction\n",
    "\n",
    "Generalization: 사용되지 않았던 새로운 예시들을 올바르게 분류하는 능력\n",
    "\n",
    "### 1.1 다항식 곡선(Polynomial Curve)\n",
    "\n",
    "우리의 목표는 training set을 사용해 새로운 입력값 $\\hat{x}$이 주어졌을 때, Target Variable $\\hat{t}$를 예측하는 것이다. 우리가 앞으로 살펴볼 것처럼 기저에 있는 함수 $sin(2{\\pi}x)$를 찾아내는 것이 예측과정에 암시적으로 포함된다. 이는 한정된 데이터 집합으로부터 Generalization을 시행하는 과정이 필요하기 때무에 본질적으로 어려운 문제이다. 게다가 Observed data들은 Noise로 인해 변질되어 있어서 각각의 주어진 $\\hat{x}$에 대해 어떤 값이 적합한 $\\hat{t}$인지 불확실하다.\n",
    "\n",
    "확률론(1.2)에서는 이러한 불확실성을 정확하고 정량적으로 표현하는데 도움을 주고 \n",
    "의사결정이론(1.5)에서는 특정 기준에 따라 최적의 예측을 하는 데 확률적인 표현을 활용할 수 있게 해준다.\n",
    "\n",
    "- $sin(2{\\pi}x)$에서 random noise 섞은 데이터가 10 개일 때\n",
    "\n",
    "9차에서 오차 0 $\\to$ 당연, 해당 다항식은 $w_0$ ~ $w_9$까지 10차의 자유도를 갖고 있고 데이터도 10개이므로 but Overfitting\n",
    "\n",
    "데이터가 많으면, 복잡한(유연한) 모델을 활용한 피팅이 가능. 모델의 복잡도를 측정하는데 매개변수의 숫자만을 사용하는 것이 아닌 더 적합한 방법이 존재한다. (3장 선형회귀모델, Linear Regression Model)\n",
    "\n",
    "지금의 예시에서 사용한 최소제곱법(least squares approximation)은 최대 가능도(Maximum Liklihood 1.2.5)의 특별한 사례이다. Overfitting 문제는 Maximum Liklihood 방법의 성질 중 하나로써 이해가 가능하다. Bayesian 방법론을 채택하면 과적합 문제를 피할 수가 있다. Bayesian 관점에서는 데이터 포인트의 숫자보다 매개변수의 숫자가 훨씬 더 많은 모델을 사용해도 문제가 없다는 것을 앞으로 볼 것이다. Bayesian 모델에서는 데이터 집합의 크기에 따라서 적합한 매개변수의 수가 자동으로 정해진다.\n",
    "\n",
    "비교적 복잡하고 유연한 모델을 제한적인 숫자의 데이터 집합을 활용해 Fitting 할 때 자주 사용되는 기법이 Regularization 이다. Error Function에서 penalty항을 추가하는 것이다.\n",
    "\n",
    "$\\tilde{E}(w) = {1\\over 2}{\\Sigma \\{ y(x_{n},\\mathbf{w}) - t_{n} \\} ^{2} + {\\lambda \\over 2}  {\\parallel}{\\mathbf{w}}{\\parallel}^2  }$\n",
    "\n",
    "$ {\\parallel}{\\mathbf{w}}{\\parallel}^2 \\equiv {\\mathbf{w}}^{T}{\\mathbf{w}} = w^{2}_{0} + w^{2}_{1} + w^{2}_{2} + ... + w^{2}_{M}   $이고 계수  ${\\lambda}$ 가 정규화항의 제곱합 Error Function에 대한 상대적인 중요도를 결정짓는다. ${w_{0}}$을 포함하면 Target Variable의 원점을 무엇으로 선택택하느냐에 대해 결과가 종속되므로, 종종 ${w_{0}}$는 정규화항에서 제외한다. ${w_{0}}$만 따로 빼내어 별도의 정규화 계수와 함께 다른 항을 만들어 포함하기도 한다. (5장 5.1)\n",
    "\n",
    "$\\tilde{E}(w)$ 의 최솟값을 찾는 문제 역시 닫힌 형식이기 때문에 앞에서 미분을 통해 유일해를 찾아낼 수 있다. 통계학에서는 계수의 크기를 수축시키는 방법을 사용하여 수축법(Shrinkage Method)라고 하고, Quadratic(이차 형식) 정규화는 Ridge Regression이라고 부룬다. Neural Network의 맥락에서는 이를 Weight Decay(가중치 감쇠)라 한다.\n",
    "\n",
    "위에서 M = 9 일 때, Overfitting이 일어난 식에 $ln\\lambda = -18$ 을 적용하면 Overfitting을 피할 수 있다. 그러나 람다가 너무 크면 좋지 않다. 모델의 복잡도와 람다의 관계는 1.3 에서 자세히 본다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### 1.2 확률론\n",
    "\n",
    "Pattern Recognition 에서 중요한 concept 중 하나는 바로 **Uncertainty** 이다. <br> \n",
    "불확실성은 측정할 때의 노이즈를 통해서도 발생하고, 데이터 집합 수가 제한되어 있다는 한계점 때문에도 발생한다.<br>\n",
    "확률론은 불확실성을 계량화하고 조작하기 위한 이론적인 토대를 마련하며, 패턴 인식의 중요한 기반이다.<br>\n",
    "1.5절의 의사결정이론과 확률론을 통해, 주어진 정보가 불확실하거나 완전하지 않은 제약 조건하에서 최적의 예측을 시행할 수 있게 한다.\n",
    "\n",
    "\n",
    "* Sum Rule & Product Rule\n",
    "<br>\n",
    "Sum Rule : $p(X = x_{i}, Y = y_{i}) = {n_{ij} \\over N }$ 일 때, &nbsp; $p(X = x_{i}) = {\\sum_{j = 1}^L}p(X = x_{i}, Y = y_{i}) $ 이 때,  $p(X = x_{i})$를 Marginal probability(주변확률)라고 불린다.\n",
    "<br> \n",
    "Product Rule : $p(X = x_{i}, Y = y_{j}) = {n_{ij} \\over N} = {{n_{ij}\\over c_{i}} \\cdot {c_{i} \\over N} = p(Y = y_{j}|X=x_{i})p(X=x_{i}) }$\n",
    "\n",
    "* Bayes' Theorem\n",
    "<br>\n",
    "곱의 법칙과 대칭성 $p(X,Y) = p(Y,X)$ 로부터 베이즈 정리를 도출할 수 있다.<br>\n",
    "$p(Y|X) = {p(X|Y)p(Y) \\over p(X)}$\n",
    "\n",
    "ex) Red Basket에 오렌지 6개, 사과 2개 / Blue Basket에 오렌지 1개, 사과 3개 / $p(B = red)$ = 4/10 , $p(B = blue)$ = 6/10\n",
    "<br>\n",
    "어떤 과일이 선택되었는지를 알기 전에 어떤 박스를 선택했냐고 묻는다면 그 확률은 어떤 과일이 선택되었는지 관찰하기 '전'의 확률 == 사전확률(Prior Probability) p(B)라고 한다. \n",
    "<br>\n",
    "선택된 과일이 오렌지라는 것을 알게 된다면 Bayes' Theorem을 활용해 $p(B|F)$를 구할 수 있고 이는 사후확률(Posterior Probability) 이다.\n",
    "<br>\n",
    "예시에서 빨간색 상자를 고를 사전확률은 4/10 이므로 파란색 상자를 고를 확률이 더 높다. 그러나 선택된 과일이 오렌지라는 것을 확인하고 난 후 빨간색 상자를 고를 사후 확률이 2/3이므로 우리가 고른 상자가 빨간색 상자이었을 확률이 더 높게 된다. 따라서 고른 과일이 오렌지였다는 관측결과가 고른 상자가 빨간색일 가능성으르 높여주는 우리의 직관과 일치한다. 오렌지를 골랐다는 증거가 강력해 사전지식을 뒤엎고 빨간 상자를 골랐을 확률을 높게 만들어 주는 것이다.\n",
    "<br>\n",
    "$p(F|B) = p(F)$가 된다. 과일을 고를 확률은 어떤 상자를 골랐는 지와는 독립이다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.1 Probability density (확률밀도)\n",
    "\n",
    "연속적인 변수에서의 확률을 알아보자. 실수 변수 x가 $(x,x+\\delta x)$ 구간 안의 값을 갖고 그 변수의 확률이 $p(x)\\delta x (\\delta x \\to 0 일\\  경우) $로 주어진다면, p(x)를 x의 확률밀도(probability density)라고 부른다. 이때 x가 (a,b) 구간 사의 값을 가질 확률은 다음과 같이 주어진다.\n",
    "<br>\n",
    "$$p(x \\in (a,b)) = {\\int_{a}^{b} p(x)dx} $$\n",
    "<br>\n",
    "그리고  다음 두 조건을 만족해야한다. $p(x)\\ \\geqslant 0$ and $\\int_{-\\infty}^{\\infty}p(x)dx = 1 $\n",
    "\n",
    "확률 분포(probability distribution) 함수는 야코미안 인자로 인해서 비선형 변수 변환 시에는 일반적인 단순 함수와는 다른 방식으로 변화하게 된다. 예를들어, $x = g(y)$의 변수 변환을 고려해 보자. 그러면 함수 $f(x)$는 $\\tilde{f}(y) = f(g(y))$가 된다. x의 확률밀도함수(PDF) $p_{x}(x)$와 새로운 변수 y의 PDF $p_{y}(y)$를 살펴보면 둘이 다른 확률밀도를 가진 다는 것이 자명하다.<br>\n",
    "$(x,x+\\delta x)$범위에 속하는 관찰값(아주 작은 $\\delta x$에 대해)은 범위 $(y,y+\\delta y)$로 변환될 것이며, 이때 $p_{x}(x)\\delta x \\simeq\n",
    "p_{y}(y)\\delta y$다. 따라서 다음과 같다.\n",
    "$${p_{y}(y) = p_{x}(x) \\left|{dx \\over dy  }\\right| = p_{x}(g(y)) \\left|g^{\\prime}(y)\\right| }$$\n",
    "이로부터, 확률 밀도의 최댓값은 어떤 변수를 선택하는지에 따라 달라짐을 알 수 있다.\n",
    "x가 $(-\\infty,z)$ 범위에 속할 확률은 누적 분포 함수(CDF)로 표현된다.\n",
    "$$P(z) = \\int_{-\\infty}^{z} p(x)dx $$\n",
    "따라서, 확률 밀도는 누적분포함수의 미분으로 표현할 수 있다.\n",
    "만약 여러 개의 연속적인 변수가 주어지고 변수들이 벡터 x로 표현될 경우에도 적분을 전체 x 공간에 대해 시행한다.<br> 만약 x가 이산 변수일 경우 p(x)를 확률질량함수라고 부르기도 한다. 연속변수의 확률밀도와 이산변수와 연속변수가 조합된 경우의 확률 밀도에도 합의 법칙, 곱의 법칙, 베이지안 정리를 적용할 수 있다. ex) $p(x) = \\int p(x,y)dy \\ \\ \\ \\ \\ \\ \\ \\ \\ p(x,y) = p(y|x)p(x)$ <br>\n",
    "연속변수의 합과 곱의 법칙에 대해 정식으로 정의를 내리기 위해서는 **측도이론(measure theory)**에 대해 살펴봐야한다. 간략히 설명하면 측도이론에서 각각의 실수 변수를 폭 $\\Delta$인 범위들로 쪼개고 각각의 범위를 이산 확률 분포로 간주한다. 여기서 $lim \\Delta \\to 0$를 취하고 합을 적분으로 바꾸면 우리가 원하는 결과를 얻는다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.2 기댓값과 공분산 (Expectation & Covariance)\n",
    "\n",
    "확률과 관련된 가장 중요한 계산 중 하나는 함숫값들의 가중 평균을 구하는 것이다. 확률 밀도 p(x)하에서 어떤 함수 f(x)의 평균값은 f(x)의 기댓값(Expectation)이라 하며, $\\mathbb{E}[f]$라 적는다.\n",
    "$$ \\mathbb{E}[f] = \\sum_{x} p(x)f(x) \\qquad \\mathbb{E}[f] = \\int p(x)f(x)   $$\n",
    "각각 이산분포 연속분포일 경우 이다.\n",
    "<br>\n",
    "만약 유한한 N개의 포인트를 확률 분포 또는 확률 밀도에서 추출 했다면, 이산/연속 모든 경우에 각 포인트들의 유한한 합산으로 기댓값을 근사할 수 있다.\n",
    "$$ \\mathbb{E}[f]  \\simeq {1\\over N} \\sum_{n=1}^{N}f(x_{n})  $$\n",
    "**11장 표본추출방법론**에서 이 결과를 많이 활용한다.([1] week 10 Sampling Based Inference) 위 식에서 $lim N \\to \\infty$일 때 정확한 값이 된다.<br>\n",
    "다변수 함수의 기댓값을 구할 경우에는 어떤 변수에 대해 평균을 내는지 지정하여 계산할 수 있다. f(x,y)의 평균값을 x의 분포에 대해 구하라는 것은 $\\mathbb{E}_{x}[f(x,y)]$ 이다. 조건부 분포에 해당하는 조건부 기댓값(conditional expectation)은  $\\mathbb{E}_{x}[f(x|y)] = \\sum_{x}p(x|y)f(x)$이며, 연속변수에서도 마찬가지로 정의 가능하다.\n",
    "\n",
    "분산(Variance)은 다음과 같이 정의된다.\n",
    "$$var[f] = \\mathbb{E}[(f(x)- \\mathbb{E}[f(x)])^{2}]$$\n",
    "위 식을 전개하면 분산을 $f(x)$와 $f(x)^2$의 기댓값으로 표현가능하다. $var[f] = \\mathbb{E}[f(x)^{2}] - \\mathbb{E}[f(x)]^2$ <br>\n",
    "변수 x 그 자체로는 $var[x] = \\mathbb{E}[x^{2}] - \\mathbb{E}[x]^2$ 이다.\n",
    "\n",
    "두 개의 확률 변수 x와 y에 대한 공분산(covariance)는 다음과 같이 정의된다.\n",
    "$$var[x,y] = \\mathbb{E}_{x,y}[(x - \\mathbb{E}[x])(y - \\mathbb{E}[y])]  = \\mathbb{E}_{x,y}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]$$\n",
    "공분산은 x값과 y값이 얼마나 함께 변동하는 가의 지표이며, 만약 x와 y가 서로 독립일 경우 공분산값은 0으로 간다.<br>\n",
    "두 확률 변수 x,y 가 벡터일 경우 공분산은 행렬이 된다.\n",
    "$$var[x,y] = \\mathbb{E}_{x,y}[(x - \\mathbb{E}[x])(y^{T} - \\mathbb{E}[y^{T}])]  = \\mathbb{E}_{x,y}[xy^{T}] - \\mathbb{E}[x]\\mathbb{E}[y^{T}]$$\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.3 베이지안 확률 (Bayesian Probability)\n",
    "\n",
    "Q. What is probability?<br>[1]\n",
    "$\\to$ a. ** Frequentistic view ** : It is the ** relative frequency ** with which outcom would be obtained if the process were repeated a large number of times under similar conditions. <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;b. Bayesian: It is your degree of belief in an outcome. \n",
    "\n",
    "'북극의 빙하가 이번 세기말까지 다 녹아 없어진다'는 사건을 생각 해보면 여러 번 반복할 수 없어 앞에서 본 과일 상자와 같은 방식으로 확률을 정의하는 것이 불가능하다. 그러나 우리는 이러한 사건들에 '북극의 얼음이 어러저러한 속도로 녹는다'와 같은 견해가 있으며 새로운 증거를 추가할 수 있다면 얼음이 녹는 속도에 대한 우리의 의견을 수정할 수 있다. 그리고 이러한 상황들에서 우리는 주어진 불확실성을 정량화할 수 있으며 새 증거가 주어질 때마다 불확실성을 수정해 최적의 선택을 내리게 해주는 일반적인 방법론이 확률의 베이지안 해석이다.\n",
    "\n",
    "불확실성을 나타내는 도구로써의 확률은 임의적으로 선택된 것이 아니다. 상식을 바탕으로 이성적으로 추론한다면 확률을 사용하는 것이 피할 수 없는 선택이라는 것을 알 수 있다. \n",
    "\n",
    "확률에 대한 개념을 일반적으로 확장하는 것은 패턴인식에서 큰 도움이된다. 1.1절의 다항식 곡선 피팅에서 관찰값 $t_{n}$에 대해서는 확률의 Frequentistic 관점이 적합해 보일 수 있다. 그러나 적합한 모델 매개변수 w를 정하는 데 있어 불확실성을 수치화하고 표현하려면 베이지안 관점을 사용하면 확률론의 다양한 장치들을 활용해 w와 같은 모델 매개변수의 불확실성을 설명할 수 있다. 더불어 베이지안 관점은 모델 그 자체를 선택하는데 있어서도 유용하다.\n",
    "\n",
    "가능도 함수(Likelihood function)는 Frequentistic, Bayesian 둘 다 중요하다. 머신러닝 문헌에서는 종종 음의 로그 가능도 함숫값을 error function으로 사용한다.\n",
    "\n",
    "[MLE MAP 설명 및 계산](https://github.com/NamSahng/Summary/blob/master/Intro2AI%26ML/W1%20MLE%20%26%20MAP.ipynb) [1]\n",
    "\n",
    "Frequentistic view로서 오차를 측정하는 방법 중 하나가 **부트스트랩(bootstrap)** 이다. Bootstrap 에서는 다음과 같은 방식으로 데이터 집합을 만든다. \n",
    "\n",
    "베이지안 관점의 장점 중 하나는 사전지식을 추론과정에 포한할 수 있다는 것이다. 합리적인 사전 확률을 사용하면 과도한 결론에 치우치지 않는다.\n",
    "\n",
    "사전 분포에 대해 의존도를 낮추기 위해 무정보적(noninformative) 사전 분포를 사용하는 경우도 있지만 이는 서로 다른 모델들을 비교하는 것을 어렵게 만든다. 그리고 실제로 좋지 않은 사전분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 높은 확신으로 내놓기도 한다. Frequentistic 의 평가 방법인 **Cross Validation(교차검증법)**과 같은 테크닉을 모델 비교할 수 있다.\n",
    "\n",
    "베이지안 방법론은 지난 수년간 실용적 측면에서 중요도를 키워왔으며, Pattern Recognition and Machine Learning은  베이지안 관점에 큰 가중치를 두지만, 필요할 경우 Frequensic view의 concept에 대해서도 논의할 것이다. 베이지안 방법론의 토데는 18세기에 만들어졌지만 실제로 활용하는데 있어 전체 매개변수 공간에 대한 주변화(합산 또는 적분, Marginalization(?))와 같은 제약이 있었다. 예측치를 계산하거나 모델을 비교하는데 필요하기 때문이다. **Marcov Chain이나 Monte Carlo** (11장) 등의 표본 추출 방법이 개발되고, 컴퓨터 하드웨어의 발전으로 베이지안 테크닉을 실제로 사용할 수 있었다. 몬테카를로 방법론은 아주 유연하여, 다양한 범위의 모델에 적용할 수 있으나 연산량이 많아 작은 규모의 문제에서만 사용했었다. 최근에는 **Variational Inference(변분적 추론, 변분적 베이지안), Belief Propagation(기대 전파법)(10장)** 등의 효율적인 결정론적 근사 방법들이 개발 되었다. 이를 바탕으로 더 큰 규모의 문제들에 베이지안 테크닉을 적용할 수 있었다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.4 가우시안 분포(Gaussian distribution)\n",
    "\n",
    "정규분포(normal distribution)이라고도 불리며 단일 실수 변수 x에 대해서 가우시안 분포는 \n",
    "$$ \\mathcal{N}(x | \\mu , \\sigma ^{2} ) = {{1}\\over{(2 \\pi \\sigma ^{2})^{1/2}}}exp \\left\\{ {- {1 \\over {2 \\sigma ^{2}}}(x - \\mu)^{2}     } \\right\\}  $$\n",
    "\n",
    "평균 분산 표준편차는 위에 보이는 것이고, $\\beta = 1/\\sigma^{2}$는 정밀도(precision)이라 한다. \n",
    "\n",
    "다음은 연속 변수로 이루어진 D차원 벡터 x에 대한 가우시안 분포이다.\n",
    "$$ \\mathcal{N} (x | \\mu , \\Sigma ) = {{{1} \\over {2 \\pi ^{D/2}}} {{1} \\over {\\left\\vert \\Sigma \\right\\vert ^{1/2} }}}exp  \\left\\{  {-{1 \\over 2}(x - \\mu)^{T}\\Sigma ^{-1} (x - \\mu)  }  \\right\\} $$\n",
    "D차원 벡터 $\\mu$는 평균값, D X D 행렬 $\\Sigma$는 공분산이라 한다. 그리고 $\\left\\vert \\Sigma \\right\\vert $는 $\\Sigma$의 행렬식이다. 다변량 가우시안 분포에 대해서 간단히 보고 자세한 것은 2.3 절에서 보자.<br>\n",
    "관측된 데이터 $\\mathbf{x} = (x_{1}, ...x_{N})^T$를 살펴보면 관측된 N개의 스칼라 변수 $x$를 지칭한다. 여가서 벡터값을 갖는 변수의 한 관측값 $(x_{1}, ...x_{N})^T$과 구별하기 위해서 $\\mathbf{x}$를 사용했다. 평균값과 분산을 갖는 가우시안 분포에서 관측값들을 독립적으로 추출한다고 가정할 것이며 데이터 집합으로 부터 이 매개변수들을 결정하는 것이 우리의 목표이다. 같은 분포에서 독립적으로 추출된 데이터 포인트들을 **독립적이고 동일하게 분포(independent and identically distributed, i.i.d)**되었다고 한다. 두 독립사건의 결합확률은 주변확률의 곱이므로, 우리의 데이터 집합 $\\mathbf{x}$는 i.i.d 이기 때문에 $\\mu , \\sigma ^2$가 주어질 때 조건부 확률을 다음과 같이 적을 수 있다.\n",
    "$$ { p(x | \\mu , \\sigma ^{2} ) = {\\prod_{1}^{N}  \\mathcal{N}(x_{n}|\\mu , \\sigma ^{2} ) }  }$$\n",
    "위 식을 $\\mu, \\sigma ^{2}$의 함수로 보면 가우시안 분포의 가능도 함수에 해당한다.<br>\n",
    "관측된 데이터 집합을 바탕으로 확률 분포의 매개변수를 결정하는 표준적인 방법 중 하나는 MLE로 차즌 것이다. 주어진 데이터를 바탕으로 매개변수의 확률을 최대화하는 것이 주어진 매개변수를 바탕으로 데이터의 확률을 최대화하는 것보다 더 자연스럽게 느껴지므로 조금 이상하게 보일 수도 있다. 사실, 이 두 방법은 깊은 연관성을 갖는데 1.2.5의 곡선피팅 예시를 바탕으로 논의 해 볼것이다.\n",
    "<br>\n",
    "먼저 MLE로 알려지지 않은 가우시안 분포의 매개변수 $\\mu, \\sigma ^{2}$를 찾는 것을 계속해 보자. 로그를 취한 후 최댓값을 찾는 것은 동일하며, 곱셈의 언더플로우 문제를 방지가능하므로 이를 취하자.(30pg) 그리고 식의 $\\mu, \\sigma ^{2}$의 MLE의 해, 표본 평균(sample mean)과 표본 분산(smaple variance)의 값일 때이다.\n",
    "\n",
    "이 장의 뒷부분과 책의 나머지 부분에서는 MLE의 한계점에 대해 자세히 말할 것이다. 여기서는 우리가 현재 다루고 있는 단변량 가우시안 분포를 기준으로 MLE를 통해 계산한 매개변수 값이 어떤 문제를 갖고 있는지 간단히 보자. MLE는 구조적으로 분포의 분산을 과소평가하게 될 수 있다. 이를 **편향(Bias)**의 예시로, 다항식 곡선 피팅에서 살펴본 과적합(Overfitting)과 연관있다. <br>\n",
    "MLE의 해인 $\\mu_{ML}, \\sigma_{ML}^{2}$에서 평균적으로 $\\mu$의 추정은 올바르게 구할 수 있지만 분산은 (N-1)/N 만큼 과소평가하게 된다. 31pg 아래 그림에서 직관적으로 확인 가능하다. 그러나 데이터 개수인 N이 커질수록 문제가 되지 않으면 무한대로 가면 원 분포와 같아진다. 그러나 책 전반에 걸쳐 우리는 많은 매개변수를 포함한 복잡한 모델을 살펴봄에 따라 MLE와 관련된 편향(Bias) 문제는 더욱 심각해진다. MLE의 편향(Bias)문제는 우리가 앞서본 다항식 곡선의 피팅에서의 과적합 문제의 근본적인 원인에 해당한다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.5 곡선 피팅\n",
    "\n",
    "앞에서 다항식 곡선 피팅 문제를 오차 최소화의 측면에서 살펴보았지만 확률적 측면에서 살펴봄으로써 오차함수와 정규화에 대한 통찰을 얻을 수 있으며 완전한 베이지안 해결법을 도출하는 데 도움을 줄 수 있다.\n",
    "<br>\n",
    "곡선 피팅 문제의 목표는 N개의 입력값 $\\mathbf{x} = (x_{1}, ...x_{N})^T$과 해당 표적값 $\\mathbf{t} = (t_{1}, ...t_{N})^T$에서 새로운 입력변수 x가 주어졌을 때, 타겟 변수 t를 예측하는 것이다. 확률 분포를 이용해 타겟 변수 값에 대한 불확실성을 표현할 수 있으며 이를 위해 주어진 x값에 대한 t 값이 $y(x,\\mathbf{w})$를 평균으로 갖는 가우시안 분포를 갖는다고 가정할 것이다. 여기서, $y(x,\\mathbf{w})$는 앞의 식 $y(x,\\mathbf{w}) = \\sum_{j = 0}^{M}w_{j}x^{j}$에서 주어진 다항식 곡선이며 다음의 조건부 분포를 갖는다. \n",
    "$ p(t | x , \\mathbf{w}, \\beta) =  \\mathcal{N}(t, y(x,\\mathbf{w}), \\beta ^{-1}) \\ \\ \\ $ where $\\beta ^{-1} = \\sigma ^{2} \\qquad$  이 식을 도식화 한것이 32pg 아래 그림 \n",
    "<br>\n",
    "이제 training set {$\\mathbf{w, t}$}을 바탕으로 MLE를 통해 알려 지지 않은 매개변수 $\\mathbf{w}, \\beta$를  구해보자. 데이터가 위 식에서 독립적으로 추출되었다고 가정하면 우리의 가능도 함수는 다음과 같다.\n",
    "$${ p(\\mathbf{t} | x , \\mathbf{w}, \\beta) = {\\prod_{n=1}^{N} \\mathcal{N}(t_{n}, y(x,\\mathbf{w}), \\beta ^{-1}) }} \\qquad [f \\ 1.61] $$\n",
    "앞과 같이 로그를 취해 로그 가능도 함수를 만들면 \n",
    "${ p(\\mathbf{t} | x , \\mathbf{w}, \\beta) = - { \\beta \\over 2} \\sum_{n = 1}^{N}\\left\\{ {y(x_{n}, \\mathbf{w}) - t_{n} } \\right\\}^{2} + {N \\over 2}ln{\\beta} - {N \\over 2}ln(2 \\pi) }$ 가 된다.  $[f  1.62]$ <br>\n",
    "첫 번째로 다항식 계수의 최대 가능도 해를 구하자.($ \\mathbf{w}_{ML}$) $ \\mathbf{w}$ 에 대해 위 식이 최대로 만드는 값을 구하면 되므로 오른 쪽 두항을 제외 할 수 있으며 로그에 양의 상수를 곱해도 최대값의 위치는 변함이 없으므로 $\\beta / 2$를 1/2로 변환 가능하다. 마지막으로 로그 가능도를 최대화하는 대신에 로그 가능도의 음으로 두고 최소화를 하는 것은 같다. \n",
    "<br>\n",
    "결과적으로 $\\mathbf{w}$를 구하기 위해 MLE를 하는 것은 앞서 본(1.1절) Error function(오차함수) $E(\\mathbf{w}) = { 1 \\over 2} \\sum_{n = 1}^{N}\\left\\{ {y(x_{n}, \\mathbf{w}) - t_{n} } \\right\\}^{2} $ 과 같다는 것을 알 수 있다. 노이즈가 가우시안 분포를 가진다는 가정하에 MLE의 결과로 **제곱합 오차함수**를 유도할 수 있는 것이다. \n",
    "<br>\n",
    "마찬가지로 가우시안 조건부 분포의 정밀밀도 매개변수 $\\beta$를 결정하는 데도 MLE를 사용하면,  $ {1 \\over {\\beta_{ML}}} = {{1 \\over{N}}\\sum_{n=1}^{N}\\left\\{ {y(x_{n}, \\mathbf{w}_{ML}) - t_{n} } \\right\\}^{2}  }$ 이다.<br> 매개변수 벡터 $ \\mathbf{w}_{ML}$을 먼저 구해 이를 이용해 정밀도 ${\\beta_{ML}}$를 구할 수 있다.\n",
    "\n",
    "매개변수 $\\mathbf{w} , \\beta$를 이용해 새로운 변수 x에 대한 예측값을 구할 수 있다. 확률모델을 사용하므로, 전과 같이 하나의 점추정값이 아닌 t에 대한 **예측 분포(predictive distribution)**으로 표현될 것이다. 최대 가능도 매개변수들을 form 1.61에 대입하면 다음을 얻을 수 있다.\n",
    "\n",
    "$$ p(t|x,\\mathbf{w}_{ML}, \\beta_{ML}) =  \\mathcal{N}(t|y(x,\\mathbf{w}_{ML}), \\beta ^{-1}_{ML})  $$\n",
    "\n",
    "여기서 베이지안의 방식으로 나가기 위해 다항 계수 $\\mathbf{w}$에 대한 사전분포를 도입하고, 문제를 단순화를 위해 다음 형태를 지닌 가우시안 분포를 사용하자. \n",
    "<br>\n",
    "$$ p(\\mathbf{w}|\\alpha) = \\mathcal{N}(\\mathbf{w}|0 , \\alpha^{-1}\\mathbf{I}) = \\left( {{\\alpha} \\over {2\\pi}} \\right) ^{(M+1)/2}exp \\left\\{  {- {{\\alpha} \\over {2}} \\mathbf{w}^{T} \\mathbf{w} } \\right\\} \\qquad [f \\ 1.65]$$ \n",
    "\n",
    "여기서, $\\alpha$는 분포의 정밀도, M+1은 M차수 다항식 벡터 $\\mathbf{w}$의 원소의 개수이다. $\\alpha$와 같이 모델 매개변수의 분포를 제어하는 변수들을 **hyperparameter(초매개변수)**라고 한다. 베이지안 정리에 따라 Posterior는 likelihood와 prior의 곱에 비례하므로 \n",
    "$ p(\\mathbf{w} | \\mathbf{x} , \\mathbf{t}, \\alpha , \\beta) \\propto p(\\mathbf{t} | \\mathbf{x} , \\mathbf{w}, \\beta) \\ p(\\mathbf{w} | \\alpha)  $ 이며 이제 주어진 데이터에 대해 가장 높은 $\\mathbf{w}$를 찾는 방식으로 $\\mathbf{w}$를 결정할 수 있다. 다시 말해 사후분포를 최대화하는 방식으로 $\\mathbf{w}$를 결정할 수 있다는 것으로 이 방법이 **MAP(maximum posterior) 최대사후분포**이다. \n",
    "위식에 음의 로그를 취하고 f 1.62와 f 1.65를 결합하면 사후확률의 최댓값을 찾는 것은 다음과 같다.\n",
    "\n",
    "$$ { {\\beta} \\over{ 2}} \\sum_{n=1}^{N} \\left\\{  {y(x_{n}, \\mathbf{w}) - t_{n} } \\right\\}^{2}  + { {{\\alpha} \\over {2}} \\mathbf{w}^{T} \\mathbf{w} }  $$\n",
    "\n",
    "따라서 사후 분포를 최대화 하는 것이 정규화 매개변수가 $\\lambda = \\alpha / \\beta$로 주어진 식\n",
    "$\\tilde{E}(w) = {1\\over 2}{\\Sigma \\{ y(x_{n},\\mathbf{w}) - t_{n} \\} ^{2} + {\\lambda \\over 2}  {\\parallel}{\\mathbf{w}}{\\parallel}^2  }$\n",
    "의 정규화된 제곱합 오차 함수를 최소화 하는 것과 동일함을 확인할 수 있다.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "#### 1.2.6 베이지안 곡선 피팅\n",
    "\n",
    "비록 사전 분포 $p(\\mathbf{w}|\\alpha)$를 포함시키긴했지만 여전히 $\\mathbf{w}$에 대해 점 추정을 하고 있어 완벽한 베이지안 방법론을 구사하진 않는다. 완전한 베이지안적 접근을 위해 확률의 합의 법칙과 곱의 법칙을 일관적으로 적용해야한다. 이를 위해서 모든 $\\mathbf{w}$ 값에 대해 적분을 해야한다. 이러한 **'주변화'**(marginalization)가 패턴인식에서의 베이지안 방법론의 핵심이다.<br>\n",
    "곡선 피팅 문제의 목표는 training set $\\mathbf{x}, \\mathbf{t}$가 주어진 상황에서 새로운 변수 $x$에 대한 표적값 $t$를 예측하는 것이므로 예측분포 $p(t|x,\\mathbf{x},\\mathbf{t})$를 구해보자. 여기서 매개변수 $\\alpha, \\beta$는 고정되어 있으며, 미리 알려졌다고 가정한다.(이 후에 이러한 매개변수를 베이지안 적으로 데이터에서 유추하는 방법에 대해 논의할 것이다. EM?) <br>\n",
    "단순히 말하면 베이지안 방법은 단지 확률의 합과 곱의 법칙을 계속 적용하는 것으로 예측 분포를 다음과 같은 형태로 표현할 수 있다.\n",
    "$$p(t|x,\\mathbf{x},\\mathbf{t}) = \\int{p(t|x,\\mathbf{w})p(\\mathbf{w}|\\mathbf{x},\\mathbf{t})} \\ d\\mathbf{w} \\qquad f \\ 1.69 $$\n",
    "여기서 $p(t|x,\\mathbf{w})$은 위의 식  $ p(t | x , \\mathbf{w}, \\beta) =  \\mathcal{N}(t, y(x,\\mathbf{w}), \\beta ^{-1})$에서 주어진 것이다. 간략한 표기를 위해 $\\alpha$와 $\\beta$에 대한 종속성을 생략하고 적지 않았다. $p(t|x,\\mathbf{x},\\mathbf{t})$은 매개변수들에 대한 Posterior(사후분포)이며 f 1.66 의 오른쪽 변을 저규화함으로써 구할 수 있다. 3.3절에서는 곡선 피팅 예시와 같은 문제의 경우 사후 분포가 가우시안이며, 해석적으로 계산할 수 있다는 것에 대해 살펴볼 것이다. 이와 비슷하게 f 1.68을 적분하면 예측분포가 다음과 같이 가우시안 분포로 주어진다는 것을 알 수 있다. \n",
    "$$ p(t | x , \\mathbf{x}, \\mathbf{t}) =  \\mathcal{N}(t | m(x), s^{2}(x))  $$\n",
    "where mean:  ${ \\ \\ m(x) = \\beta \\phi(x)^{T}\\mathbf{S}\\sum_{n = 1}^{N}\\phi(x_{n})t_{n} \\ \\ }$ and variance: $ { \\ \\ s^{2}(x) = \\beta^{-1} + \\phi(x)^{T}\\mathbf{S}\\phi(x) \\ \\ } $ and matrix S: $ {\\ \\   \\mathbf{S}^{-1} = \\alpha \\mathbf{I} + \\beta \\sum_{n = 1}^{N}\\phi(x_{n})\\phi(x_{n})^{T}      \\ \\  }$\n",
    "<br>\n",
    "$\\mathbf{I}$는 단위 행렬이며 $\\phi(x)$는 각각의 원소가 $i = 0,....,M$에 대해 $\\phi_{i}(x) = x^{i}$인 벡터이다.\n",
    "\n",
    "\n",
    "이를 통해 식 1.69의 예측 분포의 평균과 분산이 x에 종속되어 있음을 알 수 있다. 타겟 변수의 노이즈로 인한 예측값 t의 불확실 성이 위의 분산에 관한 식의 첫 번째 항에 표현되어 있다! 이 불확실성은 식 1.64 $p(t|x,\\mathbf{w}_{ML}, \\beta_{ML}) =  \\mathcal{N}(t|y(x,\\mathbf{w}_{ML}), \\beta ^{-1}_{ML})$의 $\\beta_{ML}^{-1}$로 이미 표현되어있다. 하지만 분산의 식 두번째 항은 $\\mathbf{w}$의 불확실성으로 부터 기인한 것이며, 베이지안 접근법을 통해 구해진 것이다. 합성 사인 함수 회귀 문제에 대한 예측 분포는 35pg 아래 표현되어있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 모델 선택(Model Selection)\n",
    "\n",
    "- 최소제곱법\n",
    "\n",
    "다항식 곡선 피팅 예시에서, 가장 좋은 일반화 값을 주는 최적의 다항식 차수가 있다는 것을 확인<br>\n",
    "다항식의 차수: 모델의 자유 매개변수의 수 결정, 모델 복잡도 결정.<br>\n",
    "정규화 계수 $\\lambda$: 모델의 복잡도 영향\n",
    "\n",
    "- 최대가능도 접근법\n",
    "\n",
    "Testset에서의 성능이 과적합으로 좋은 예측 성능 보장 못함.<br>\n",
    "Validation set, Test set 활용 가능.\n",
    "\n",
    "- LOOCV 문제점: \n",
    "\n",
    "부분에 따라 계산량 증가, 여러가지 복잡도 매개변수가 있을 때 발생.<br>\n",
    "이상적으로 training set만 활용해 여러 하이퍼파라미터와 모델 종류에 대한 비교를 한번의 훈련 과정에서 수행. training set만 활용하는 성능 척도가 필요하며 overfitting으로 인한 편향으로 자유로워야\n",
    "\n",
    "- Information Criteria(정보기준)\n",
    "\n",
    "여러 정보기준들이 최대가능도의 편향문제의 대안으로 제시.<br>\n",
    "더 복잡한 모델에서 과적합이 일어나지 않도록 페널티 항을 추가하는 것.<br>\n",
    "ex) 아카이케의 정보량기준(AIC): $ln p(D|w_{ML}) - M $ 이 가장 큰값  <br>\n",
    "where, $ln p(D|w_{ML})$: 가장 잘 피팅된 Log Likelihood, M: 모델의 수정 가능한 매개변수 수\n",
    "<br>\n",
    "베이지안 정보량기준(BIC)도 있다. 4.41절에 논의\n",
    "\n",
    "### 1.4 차원의 저주(The curse of dimensionality)\n",
    "\n",
    "Q. 오일 흐름 데이터를 분류하는 방법<br>\n",
    "-칸나누기: 입력변수의 차원이 높을 때, 필요한 칸의 수가 기하급수적으로 늘어남.\n",
    "\n",
    "Q. 다항식 곡선피팅문제에서 다변수 입력공간 적용.<br>\n",
    "$y(\\mathbf{x,w}) = w_{0} + \\sum_{i=1}^{D}{w_{i}x_{i}} + \\sum_{i=1}^{D}\\sum_{j=1}^{D}{w_{ij}x_{i}x_{j}} +  \\sum_{i=1}^{D}\\sum_{j=1}^{D}\\sum_{k=1}^{D}{w_{ijk}x_{i}x_{j}x_{k}} $<br>\n",
    "D가 증가함에 따라 독립적인 계수(x 변수들 간의 교환 대칭성 때문에 모든 계수가 독립적인 것은 아님)의 숫자는 $D^{3}$에 비례해 증가<br>\n",
    "실제 적용에서는 데이터의 복잡한 종속관계를 다 표현하기 위해 더 높은 차수의 다항식이 필요할 수도 있다. M차 다항식의 경우 계수의 숫자는 $D^{M}$에 비례해 증가한다. 이것이 기하급수적인 증가가 아니라 거듭제곱 형태의 증가이긴 하나, 여전히 이 방법을 실제 적용하기에는 증가 속도가 너무 빠르다.\n",
    "\n",
    "3차원에서의 기하학적 직관은 고차원에서 다르게 작용할 수 있다.<br>\n",
    "ex) D차원의 반지름 r = 1 인 구체에서 r = 1-e에서 r=1사이에 존재하는 부피의 피율을 계산하면 D차원에서 반지름 r을 가진 구체의 부피는 $r^{D}$에 비례하여 증가한다.<br>\n",
    "고차원의 공간에서는 구체 부피의 대부분이 표면 근처의 얇은 껍질에 집중되어 있다는 것.<br>\n",
    "ex) 패턴인식과 직접 연관된 추가적 에시: 가우시안 분포<br>\n",
    "데카르트 좌표에서 극좌표로 변환한 뒤에 방향성 변수들을 적분시켜 없애면 원점에서 부터의 반지름 r에대한 함수 p(r)로 표현되는 밀도함수를 구할 수 있다. 따라서 $p(r)\\delta{r}$은 반지름 r상에서 $\\delta{r}$의 두께에 해당하는 확률 질량을 나타내게 된다.<br>\n",
    "그림 1.23을 보면 큰 D값에 대해서 가우시안 확률 질량이 얇은 겉껍질에 집중되는 것을 확인할 수 있다.\n",
    "\n",
    "차원의 저주: 고차원에서 발생할 수 있는 심각한 문제.<br>\n",
    "1~2차원 입력공간을 예시로 할 것이지만, 고차원에서는 반드시 적용되지 않을 수 있음.<br>\n",
    "\n",
    "고차원 입력값에 대해 사용할 수 있는 효과적 패턴인식 테크닉을 찾는게 불가능 하지 않은 이유<br>\n",
    "1.실제 세계의 고차원 데이터들의 경우 유의미한 차원의 수는 매우 제한적인 경후가 많다.<br>\n",
    "2.실제 세계의 데이터는 보통(최소 지역적으로는) '매끈한' 특성이 있어 대부분 입력값에서 작은 변화가 일어나면 표적값에서도 작은 변화만 일어남.\n",
    "또 지역 보간법 등의 테크닉을 적용해 입력변수에 대한 타깃 변수 예측이 가능해진다. <br>\n",
    "성공적인 패턴 인식 테크닉은 이 특성을 활용해 만들어 지는 경우가 많다.<br>\n",
    "ex) 컨베이어 벨트위의 물체들의 이미지를 캡처해 해당 물체의 모양을 판단 문제.<br>\n",
    "각각의 이미지는 고차원 공간의 포인트, 공간의 차원수는 픽셀의 개수에 결정. <br>\n",
    "각각의 물체는 이미지 안에 다른 위치와 다른 모양으로 나타날 수 있음 $\\to$ 3단계의 자유도 존재<br>\n",
    "그러므로 이미지 집합은 고차원의 공간 내부에 포함된 3차원의 **매니폴드(Manifold)**상에 존재 <br>\n",
    "물체의 위치, 모양, 픽셀의 강도 등은 서로 간에 복잡한 관계를 갖고 있어 이 매니폴드는 강한 비선형성을 가짐. 문제의 목표가 이미지를 입력받아 물체의 위치와 상관없이 모양만 출략하는 것이면, 매니폴드상에 중요한 자유도는 하나가 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 결정이론(Decision Theory)\n",
    "\n",
    "1.2절에서 우리는 불확실성을 정량화하고 조작하는 수학적 토대로 확률론을 살펴보았다.<br>\n",
    "패턴 인식 문제를 풀 때는 불확실성이 존재하는 상황에서 의사 결정을 내려야 하는 경우가 많다. 이런 상황에서 결정이론과 확률론을 함께 사용하면 최적의 의사결정 내릴 수 있다.\n",
    "\n",
    "추론(Inference)문제의 대표적 예시는 p(x,t)를 찾는 것이다.(regression/classification: input vector(x), target vector(t: continous / labeled))<br>\n",
    "이는 매우 어려운 문제로, 이 문제에 대한 해결책이 이 책의 많은 부분을 차지한다. t가 어떤 값을 가질 것 같은지를 바탕으로 특정 행동을 취해야 할 수도 있으며 이를 위한 이론적 토대가 바로 **결정이론** 이다.\n",
    "\n",
    "#### Q. 암환자 분류 문제\n",
    "\n",
    "$\\mathbf{x}$: 입력벡터 / $C_{1}: 암존재 \\ \\  C_{2}: 건강함$\n",
    "<br>\n",
    "일반적인 추론문제는 결합확률분포 $p(\\mathbf{x},C_{k})$를 결정하는 과정을 포함하고 있다. 해당 상황에 대해서 가장 완전하고 확률적인 설명을 알려줄 수 있는 것이 결합확률 분포!<br>\n",
    "결합확률분포는 매우 유용한 값이긴 하지만 최족적으로 우리가 하고 싶은 것은 치료할지 말지 결정하는 것! 해당 결정이 최적이기를 바라는데 이것이 바로 **결정**단계이다. 결정이론이 하려는 것은 적절한 확률들이 주어진 상태에서 어떻게 하면 최적의 결정을 내릴 수 있는가를 설명하는 것이며 추론 문제를 풀면 간단하다. (자세한 결정이론 내용은 Beiger(1985) Bather(2000)참고)\n",
    "\n",
    "의사결정에서 확률의 역할\n",
    "$$ p(C_{k} | \\mathbf{x} ) = {{p(\\mathbf{x} | C_{k}) p(C_{k})} \\over {p({\\mathbf{x}) }}} $$\n",
    "\n",
    "위의 모든 값은 결합확률분포 $p(\\mathbf{x},C_{k})$를 알면 Margininalization과 Conditioning을 활용해 구할 수 있다. <br>\n",
    "만약 우리의 목표가 $\\mathbf{x}$를 최소화하는 것이면, 직관적으로 우리는 더 높은 사후 확률을 가진 클래스를 고를 것이다. 이후에는 이 직관이 맞음을 설명하고, 일반적인 의사결정의 기준에 대해 살펴보자\n",
    "\n",
    "#### 1.5.1 오분류 비율의 최소화\n",
    "\n",
    "Decision Region(결정구역): 오분류를 줄이는 것이 목적일 때, 각 x를 가능한 클래스 중 포함하는 규칙의 입력공간의 구역 $\\mathcal{R}_{k}$<br>\n",
    "Decision Boundary(Surface): 결정 구역 사이의 경계. 결정구역은 인접할 필요 없으며 두 구역위에 있을 수도 있음.\n",
    "\n",
    "Error가 발생할 확률을 줄이는 방법(곱의 법칙을 활용해 최소화)하는 방법은 수식적으로도 올바르게 분류할 확률을 높이는 방법(극대화)과 같으며 이것이 더 쉽다.\n",
    "\n",
    "$$  p(correct) = {\\sum^{K}_{k=1} p(\\mathbf{x} \\in \\mathcal{R}_{k}, \\mathcal{C}_{k})} = {\\sum^{K}_{k=1} \\int_{\\mathcal{R}_{k}} p(\\mathbf{x}, \\mathcal{C}_{k}) d \\mathbf{x}}$$\n",
    "\n",
    "각 x가  $ p(\\mathbf{x}, \\mathcal{C}_{k})$가 최대인 클래스로 분류 되도록 $\\mathcal{R}_{k}$를 선택할 경우 위 식이 최대가 된다. 곱의 법칙을 적용하면 $ p(\\mathbf{x}, \\mathcal{C}_{k}) = p(\\mathcal{C}_{k} | \\mathbf{x})p(\\mathbf{x})$ 이며, 각각의 $\\mathbf{x}$는 가장 큰 사후 확률 $p(\\mathcal{C}_{k} | \\mathbf{x})$를 갖는 클래스로 분류되어야 함을 확인 할 수 있다.\n",
    "\n",
    "#### 1.5.2 기대 손실의 최소화\n",
    "\n",
    "실생활에서는 단순히 오분류를 줄이는 것보다 더 복잡.<br>\n",
    "예를 들어 암환자를 건강하다고 판단하는 오류가 더 심각함.<br>\n",
    "Loss Function(Cost)를 도입해 문제 공식화 가능. (효용함수(Utility)는 최대화하는 것으로 반대개념)\n",
    "\n",
    "손실행렬 $L_{kj}$을 가정하면 $\\mathbb{E}[L] = \\sum_{k} \\sum_{j} \\int_{\\mathcal{R}_{j}} L_{kj} p(\\mathbf{x},\\mathcal{C}_{k}) d\\mathbf{x} $ 로 표현가능하고, 이는 각 $\\mathbf{x}$에 대해 $\\sum_{k} p(\\mathbf{x},\\mathcal{C}_{k})$를 최소화 해야한다는 것을 의미하고, 앞과 같이 곱의 법칙을 활용하면, $p(\\mathbf{x},\\mathcal{C}_{k}) = p(\\mathcal{C}_{k}|\\mathbf{x}) p(\\mathbf{x}) $임으로 공통인자 $p(\\mathbf{x})$를 제거 할 수 있다. 따라서 기대 손실을 최소화 하는 결정 법칙은 각 $\\mathbf{x}$를 $\\sum_{k} L_{kj} p(\\mathcal{C}_{k}|\\mathbf{x}) $를 최소화하는 클래스 j에 할당하는 것이다. 각 클래스에 대한 $p(\\mathcal{C}_{k}|\\mathbf{x}) $를 알면 이 방법을 쉽게 실행할 수 있다.\n",
    "\n",
    "\n",
    "#### 1.5.3 거부 옵션\n",
    "\n",
    "결정을 내리기 힘든 지역에 대해 결정을 피할 수 있음. 손실행렬이 주어진 경우에는 기대 손실값을 최소화 하도록 거부 옵션을 확장 가능.\n",
    "\n",
    "#### 1.5.4 추론과 결정\n",
    "\n",
    "지금까지 분류문제를 **추론 단계(Inference Stage)**와 **결정 단계(Decision Stage)**로 나누었다. <br>\n",
    "추론단계: training set을 활용해 $p(\\mathcal{C}_{k}|\\mathbf{x}) $에 대한 모델을 학습시키는 단계 <br>\n",
    "결정 단계: 학습된 사후 확률들을 이용해 최적의 클래스 할다을 시행. <br>\n",
    "두가지 문제를 한 번에 풀어내는 방법도 있다. $\\mathbf{x}$에서 결정값을 돌려주는 함수(**판별함수 discriminatn function**)를 직접 학습시키는 것.\n",
    "\n",
    "사실 결정문제를 푸는 방법은 3가지다.<br>\n",
    "  \n",
    "(a) 베이지안 정리 활용: 각 클래스 $C_{k}$에 대해 조건부 확률 밀도 $p(\\mathbf{x}|\\mathcal{C}_{k})$를 구하는 추론문제를 풀고, 클래스별 사전확률 $p(C_{k})$를 구해 사후확률 $p(C_{k}|\\mathbf{x})$를 구한다. <br> 또는 이와 동일하게 결합분포 $p(\\mathbf{x},\\mathcal{C}_{k})$를 직접 모델링한 후 정규화를 통해 사후 확률을 구할 수 있다. 사후확률을 구한 후 결정 이론을 적용해 각각의 새 입력 변수 $\\mathbf{x}$에 대한 클래스를 구한다. 직간접적으로 입력값과 출력값의 분포를 모델링하는 이런 방식을 **생성 모델(Generative Model)**이라 한다. 왜냐하면 이렇게 만들어진 분포로 부터 표본을 추출함으로써 입력 공간에 합성 데이터 포인트들을 생성해 넣는 것이 가능하기 때문이다.\n",
    "\n",
    "단점: 결합분포를 찾아야 하므로, 가장 손이 많이 간다. 많은 응용 사례에서 $\\mathbf{x}$는 고차원이며, 따라서 각각의 클래스에 대해 일정 수준 이상의 조건부 밀도를 구하기 위해 큰 Training Set이 필요할 수 있다.<br>\n",
    "장점: $p(\\mathbf{x}) = \\sum_{k} p(\\mathbf{x}|\\mathcal{C}_{k}) p(\\mathcal{C}_{k}) $를 이용해 p(x)의 주변 밀도도 구할 수 있다. 이를 바탕으로 주어진 모델하에 발생 확률이 낮은 새 데이터 포인트를 미리 발견해 검출(**이상점 검출(Outlier Detectiion)**)가능.\n",
    "\n",
    "(b) **판별모델(Discriminative Model)**: 사후확률 $p(C_{k}|\\mathbf{x})$를 계산하는 추론 문제를 풀어낸 후 결정이론을 적용해 각 입력변수 x에 대한 클래스를 구함. 사후확률을 직접모델링하는 방법.\n",
    "\n",
    "장점: 분류알고리즘을 통해 결정을 내리면 a에서 결합 분포를 전부 계산하는 계산 낭비 및 데이터 요구량 감소로 더 효율적. ML에서 생성과 판별모델을 각각 사용하는 것의 장단점 논의는 많이 있어왔고 합치려는 시도도 많았다.\n",
    "\n",
    "(c) 각각의 입력값 $\\mathbf{x}$를 클래스에 사상하는 판별함수 $f(x)$를 찾는 것. 예를 들어 클래스가 2개면  $f=0, 1$로 나뉘게. 여기서는 확률론이 사용되지 않음. 추론과 결정단계를 합친 방식. \n",
    "\n",
    "단점: 사후확률 $p(C_{k}|\\mathbf{x})$을 알 수 없음.\n",
    "\n",
    "- 사후확률 $p(C_{k}|\\mathbf{x})$을 알 수 없을 때의 단점\n",
    "\n",
    "a) 위험의 최소화<br>\n",
    "손실 행렬의 값들이 때때로 변하는 금융관련 문제의 경우는 사후확률을 알 때, $\\sum_{k} L_{kj} p(\\mathcal{C}_{k}|\\mathbf{x}) $을 수정함으로 최소 위험 결정 기준을 구할 수 있음. 판별함수만 알면, 손실행렬이 변할 때마다 분류문제를 새로 풀어야 함.\n",
    "\n",
    "b) 거부옵션\n",
    "\n",
    "사후확률을 알면 주어진 거부 데이터 포인트 비율에 대해 오분류 비율(기대 손실값)을 최소화하는 거부 기준을 쉽게 구할 수 있음.\n",
    "\n",
    "c) 클래스 사전 확률에 대한 보상\n",
    "\n",
    "예를 들어, 1000개의 이미지 중 하나만 암 환자의 이미지만 있을 때 생기는 Class Imbalance 문제를 해결하기위해 training set을 balanced되게 하면 보상을 적용해야한다. 사후확률을 활용하는 것은 사전확률을 곱하고 정규화하여 보상해줄 수 있지만, 직접 판별함수를 구하는 방식은 수정이 불가능하다\n",
    "\n",
    "d) 모델들의 결합\n",
    "\n",
    "여러 다른 종류의 정보를 하나의 입력 공간으로 합치는 것보다 엑스레이 이미지를 해석하는 시스템과 혈액검사 결과 시스템을 따로 만드는 것이 효율적일 수 있다. 두 모델이 각 클래스에대한 사후확률을 제공할 때 확률의 법칙을 적용해 시스템적으로 서로 다른 출력값을 합하는 것이 가능하다. **조건부 독립(Conditional Independence)**의 성질을 이용한 가정(이미지의 분포와 혈액분포가 독립임을)하는 것이 가장 쉬운 방법이다. \n",
    "$ p(\\mathbf{x_{I}},\\mathbf{x_{B}}|\\mathcal{C}_{k})= p(\\mathbf{x_{I}}|\\mathcal{C}_{k})p(\\mathbf{x_{B}}|\\mathcal{C}_{k}) $ <br>\n",
    "$ \\begin{matrix} {p(\\mathcal{C}_{k}|\\mathbf{x_{I}},\\mathbf{x_{B}})} &\\propto& {p(\\mathbf{x_{I}},\\mathbf{x_{B}}|\\mathcal{C}_{k}) p(\\mathcal{C}_{k})} \\\\\n",
    "&\\propto& {p(\\mathbf{x_{I}}|\\mathcal{C}_{k})p(\\mathbf{x_{B}}|\\mathcal{C}_{k}) p(\\mathcal{C}_{k})} \\\\\n",
    "&\\propto& {{p(\\mathcal{C}_{k}|\\mathbf{x_{I}})p(\\mathcal{C}_{k}|\\mathbf{x_{B}})}\\over{p(\\mathcal{C}_{k})}}\n",
    "\\end{matrix}  $<br>\n",
    "사전확률 $p(\\mathcal{C}_{k})$는 클래스별 비율로 유추할 수 있다. 특정 조건부 독립 가정은 **나이브 베이즈 모델**의 예시이다. 결합 확률 분포 $p(\\mathbf{x_{I}},\\mathbf{x_{B}})$는 보통 나이브 베이즈 모델하에서 인수분해가 되지 않는다. 이후에 조건부 독립의 가정 없이도 데이터를 결합시키는 방법에 대해 살펴보자.\n",
    "\n",
    "#### 1.5.5 회귀에서의 손실 함수\n",
    "\n",
    "회귀 문제의 결정 단계에서는 각각의 x에 대해 t의 추정값 y(x)를 선택해야한다. 여기서 손실 L(t,y(x))가 발생할 때 평균(기대)손실은 $\\mathbb{E}\\left[ L \\right] = \\int \\int L(t,y(\\mathbf{x}))p(\\mathbf{x},t)d\\mathbf{x}dt$ 회귀에서 주로 사용하는  제곱손실 $L(t,y(\\mathbf{x})) = \\{ y(x)-t  \\}^{2}$ 를 대입하면 $\\mathbb{E}\\left[ L \\right] = \\int \\int \\{ y(x)-t  \\}^{2}p(\\mathbf{x},t)d\\mathbf{x}dt$ <br>\n",
    "우리의 목표는 $\\mathbb{E}\\left[ L \\right]$ 를 최소화하는 y(x)를 찾는 것. 만약 완벽하게 유연하게 함수 y(x)를 결정할 수 있다고 가정하면 [변분법](https://github.com/NamSahng/Summary)을 적용해서 다음과 같이 적을 수 있다.\n",
    "$$ {{ \\delta \\mathbb{E}\\left[ L \\right]} \\over {\\delta y(x)} } = 2 \\int \\{ y(x)-t \\}p(\\mathbf{x},t)dt $$ \n",
    "식 y(x)에 대해서 해를 구해 확률의 합과 곱의 법칙을 적용하면, 다음을 얻는다.\n",
    "$$ y(x) = {{\\int tp(x,t) dt} \\over {p(x)} } = \\int tp(t|x)dt = \\mathbb{E}_{t}\\left[ t|x \\right] $$\n",
    "위식은 x가 주어졌을 때의 t의 조건부 평균으로써의 **회귀함수**라고 한다. 52pg 아래에 결과가 시각화 되어있으며 타겟 변수가 벡터 t로 표현되는 다차원 변수일 경우에 대해서도 쉽게 확장 가능하다.<br>\n",
    "이 경우 최적의 해는 조건부 평균 $y(x) = \\mathbb{E}_{t}\\left[ t|x \\right] $이다.\n",
    "\n",
    "다른 인사이트를 위해 $ {\\{ y(x) - t \\}^{2}} = { \\{ y(x) - \\mathbb{E}\\left[ t|x \\right] + \\mathbb{E}\\left[ t|x \\right] - t \\} ^{2}} = { {\\{ y(x) - \\mathbb{E}\\left[ t|x \\right] \\} ^{2} } + 2{\\{ y(x) - \\mathbb{E}\\left[ t|x \\right] \\}} {\\{ \\mathbb{E}\\left[ t|x \\right] -t \\}} + {\\{ \\mathbb{E}\\left[ t|x \\right] - t \\}}^{2} } $<br> \n",
    "(여기서 $ \\mathbb{E}_{t}\\left[ t|x \\right]$를 $ \\mathbb{E}\\left[ t|x \\right]$로 표기)로 전개하고 이 결과를 손실함수에 대입하고 t에 대해 적분하면 교차항이 사라지며 손실을 알 수있다. \n",
    "\n",
    "$$ \\mathbb{E} \\left[ L \\right] = \\int { \\{ y(x) - \\mathbb{E}\\left[ t|x \\right] \\} ^{2} p(x) dx } + \\int var \\left[ t|x \\right] p(x) dx  $$ \n",
    "여기서 $var \\left[ t|x \\right] p(x)$ 가 손실함수가 되며, 최적의 최소 제곱 예측은 조건부 평균으로 주어진다는 것을 보여준다. 두 번째 항은 t에 대한 분포의 분산을 계산하고, 이를 x에 대해 평균을 낸 것이다. 이 항은 표적 데이터가 가진 내재적 변동성을 표현하므로 노이즈로 해석 가능하다. 이 항은 y(x)에 대해 독립이며 더 이상 줄일 수 없는 손실함수의 최솟값에 해당한다.\n",
    "\n",
    "분류와 같이 회귀 문제에서 결정을 내리는 방식은 다음과 같다. \n",
    "\n",
    "(a) 결합 밀도 $ p(x,t )$ 를 구하는 추론문제를 푼다. 다음에 정규화하여 조건부 밀도 $ p(t|x) $를 구해 최종적으로 위와 같은 조건부 평균을 구한다.<br>\n",
    "(b) 조건부 밀도 $ p(x,t) $ 를 구하는 추론문제를 풀고 조건부 평균을 구한다.\n",
    "(c) 훈련 데이터로부터 회귀함수 $ y(x) $ 를 직접 구한다.\n",
    "\n",
    "조건부 분포 $ p(t|x) $ 가 다봉 분포인 상황에서, 제곱손실이 상당히 좋지 않은 결과를 가져오기 때분에 좀 더 복잡한 제곱손실을 일반화한 **민코프스키 손실(Minkowski Loss)**을 사용할 수 있다. 민코프스키 손실의 기댓값은 다음과 같다.\n",
    "$$ \\mathbb{E} \\left[ L_{q} \\right] = \\int \\int { \\left\\vert y(x) - t \\right\\vert ^{q} p(x,t) } dx dt $$\n",
    "\n",
    " $ q = 2 $ 일 경우 제곱 손실에 해당하며 54pg에서 다양한 q값에 대한 함수 $ \\left\\vert y(x) - t \\right\\vert ^{q} $ 와 $ y-t $ 값의 그래프를 확인 할 수 있다. $ \\mathbb{E} \\left[ L_{q} \\right] $ 의 최소값은 $ q = 2 $ 일 경우에 조건부 평균으로  $ q=1 $ 일 경우에는 조건부 중간값으로, $ q \\to 0 $ 일 경우에는 조건부 최빈값으로 주어지게 된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br><br>\n",
    "### Reference:\n",
    "\n",
    "Christopher M. Bishop, 패턴인식과 기계학습 Chapter 1\n",
    "<br>\n",
    "[1] 문일철 교수님, 인공지능 및 기계학습 개론Ⅰ Week 1,7, https://www.edwith.org/machinelearning1_17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
